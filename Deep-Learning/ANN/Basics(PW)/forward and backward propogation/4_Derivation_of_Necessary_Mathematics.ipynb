{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "u-nTRiubMNBc"
   },
   "source": [
    "# Some derivation of necessary mathematics:\n",
    "\n",
    "- Vectors\n",
    "- Differentiation\n",
    "- Partial differentiation\n",
    "- Gradient of a Function\n",
    "- Maxima & Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gd1HQr1tMwzp"
   },
   "source": [
    "# Vectors:\n",
    "A vector is an object that has both a magnitude and a direction (i.e. 5km/m in north). Geometrically, we can picture a vector as a directed line segment, whose length is the magnitude of the vector and with an arrow indicating the direction. The direction of the vector is from its tail to its head.Two vectors are the same if they have the same magnitude and direction. This means that if we take a vector and translate it to a new position (without rotating it), then the vector we obtain at the end of this process is the same vector we had in the beginning.\n",
    "\n",
    "  <img src=\"https://www.storyofmathematics.com/wp-content/uploads/2020/10/parallel-vectors.png\" width=\"300\" \n",
    "     height=\"250\">\n",
    "\n",
    "\n",
    "##### Vector in 3D:\n",
    "\n",
    "  <img src=\"https://cdn1.byjus.com/wp-content/uploads/2020/10/Types-Of-Vectors1.png\" width=\"400\" \n",
    "     height=\"250\">\n",
    "\n",
    "  \n",
    "- ### Now lets derive some derivation:\n",
    "\n",
    "  <img src=\"https://github.com/entbappy/Branching-tutorial/blob/master/14..png?raw=true\" width=\"400\" \n",
    "     height=\"250\">\n",
    "  \n",
    "  -  $OA = x_\\hat{i} + y_\\hat{j}$\n",
    "  - $OB= {x}'_\\hat{i}+ {y}'_\\hat{j}$\n",
    "\n",
    "We can also represent vectors like that,\n",
    " - $\\begin{bmatrix}\n",
    "x\\\\ y\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "x & y\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "  <img src=\"https://github.com/entbappy/Branching-tutorial/blob/master/13..png?raw=true\" width=\"400\" \n",
    "     height=\"250\">\n",
    "\n",
    "$\\vec{AB}$ = Length of $AB$\n",
    "- $OA = \\hat{i}+\\hat{j}$\n",
    "- $OB=3\\hat{i}+2\\hat{j}$\n",
    "\n",
    "$\\vec{AB}= \\vec{OB}-\\vec{OA}$\n",
    "\n",
    ">$=(3-1)i + (2-1)j $\n",
    "\n",
    "$\\therefore \\vec{AB}= 2i+j$\n",
    "\n",
    "$\\left | AB \\right | = \\sqrt{2^2+1^2}$\n",
    "\n",
    ">$=\\sqrt{5}$ (Magnitude)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b_rizDMX0PS"
   },
   "source": [
    "# Differentiation:\n",
    "\n",
    "Differentiation generally refers to the rate of change of a function with respect to one of its variables. Here its similar to finding the tangent line slope of a function at some specific point.\n",
    "     \n",
    "- Connecting f,f' and f'' graphically\n",
    "\n",
    "\n",
    "### Lets derive some derivation:\n",
    "\n",
    "<img src=\"https://github.com/entbappy/Branching-tutorial/blob/master/12..png?raw=true\" width=\"400\" \n",
    "     height=\"250\">\n",
    "\n",
    "\n",
    "- $slope = \\frac{\\Delta y}{\\Delta x}$ \n",
    "- $slope = tan\\theta = \\frac{perpendicular}{base}$\n",
    "- $slope = \\frac{y_2-y_1}{x_2-x_1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoXhqugGmtj0"
   },
   "source": [
    "<img src=\"https://github.com/entbappy/Branching-tutorial/blob/master/11.png?raw=true\" width=\"400\" \n",
    "     height=\"250\">\n",
    "\n",
    "\n",
    "$\\lim_{x\\rightarrow 0} \\frac{\\Delta y}{\\Delta x} = \\frac{dy}{dx}$\n",
    "\n",
    "$\\lim_{x\\rightarrow 0} \\frac{y_2 - y_1}{\\Delta x}$\n",
    "\n",
    "$\\lim_{x\\rightarrow 0} \\frac{f(x_2)- f(x_1)}{\\Delta x}$\n",
    "\n",
    "$\\therefore \\frac{dy}{dx}=\\lim_{x\\rightarrow 0} \\frac{f(x_1 + \\Delta x)- f(x_1)}{\\Delta x}$\n",
    "\n",
    "This is the final differentiation equation.If you put any x here you will get the slope at your x point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_XbIpE4rJqK"
   },
   "source": [
    "### Lets see some formulas / rules of Differentiation:\n",
    "\n",
    "## Power Rule:\n",
    "Here we use the power rule in order to calculate the derivative and it’s pretty simple though.\n",
    "\n",
    "$$if,\\ \\mathbf{f(x)=x^n}$$\n",
    "\n",
    "$$then,\\ \\mathbf{f'(x)=n.x^{n-1}}$$\n",
    "\n",
    "**Examples**\n",
    "\n",
    "The considered function f(x) is equal to x to the fifth.\n",
    "\n",
    "$$f(x)=x^5$$\n",
    "$$f'(x)=5x^{(5-1)}$$\n",
    "$$f'(x)=5x^4$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftOLm1CAr8-h"
   },
   "source": [
    "## Product Rule:\n",
    "If a(x) and b(x) are two differentiable functions, then the product rule is used, where at first time it compute derivative of first function and at second time it compute derivative of second function.\n",
    "\n",
    "$$\\mathbf{f(x)=f(x) . g(x)}$$\n",
    "\n",
    "$$\\mathbf{f'(x) =f'(x) . g(x) + f(x) . g'(x)}$$\n",
    "\n",
    "**Example**\n",
    "\n",
    "$$f(x)=(x^4+2).cos⁡x$$\n",
    "\n",
    "$$\\Rightarrow f'(x) =4x^3.cos⁡x+(x^4+2).(-sin⁡x )$$\n",
    "\n",
    "$$\\Rightarrow  f'(x) =4x^3  cos⁡x-x^4  sin⁡x-2 sin⁡x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwqpIVhGsuMa"
   },
   "source": [
    "# Partial Differentiation:\n",
    "Now we will see the Partial Differentiation. Here, the same rules apply while obtaining derivatives with respect to one variable while keeping others constant. This term is used for Multi-Variable Functions.\n",
    "\n",
    "**Example**\n",
    "$$f(x,y)=x^4 y$$\n",
    "Obtaining partial derivative w.r.t x\n",
    "$$\\frac{\\partial (x^4 y)}{\\partial x}=4x^3 y$$\n",
    "\n",
    "Obtaining partial derivative w.r.t y\n",
    "$$\\frac{\\partial (x^4 y)}{\\partial y}=x^4$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwWZWUVXt3Qn"
   },
   "source": [
    "# Gradient of Function:\n",
    "\n",
    "* Let's say there's a function of two variable x and y $\\Rightarrow f(x,y)$\n",
    "* then $\\frac{\\partial{f}}{\\partial{x}}$ and $\\frac{\\partial{f}}{\\partial{y}}$ is partial derivative w.r.t x and y respectively\n",
    "* Now Gradient '$\\triangledown$' of f is defined as -\n",
    "$$\n",
    "\\triangledown{f} = \\begin{bmatrix}\n",
    "\\frac{\\partial{f}}{\\partial{x}} & \\frac{\\partial{f}}{\\partial{y}}\n",
    "\\end{bmatrix}^{T} = \\begin{bmatrix}\n",
    "\\frac{\\partial{f}}{\\partial{x}} \\\\ \\frac{\\partial{f}}{\\partial{y}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* Its nothing but vector of partial derivatives\n",
    "\n",
    "***EXAMPLE***\n",
    "\n",
    "$$f(x,y) = 2.x^2 + 4y$$\n",
    "\n",
    "$$\n",
    "\\triangledown{f} = \\begin{bmatrix}\n",
    "\\frac{\\partial{f}}{\\partial{x}} \\\\ \\frac{\\partial{f}}{\\partial{y}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "4x \\\\ 4\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dtmfRHTRwjFP"
   },
   "source": [
    "# Local and Global Minima:\n",
    "* For any function their can be many minimum points and among those minimum there can exist an minima point where function has the least value and this point is known as **global minima** and other minimum points are known as **local minima** point.\n",
    "* In ML/DL finding the global minima of a loss function using optimization techniques like gradient descent plays a very important role.\n",
    "\n",
    "\n",
    "- <img src=\"https://vitalflux.com/wp-content/uploads/2020/09/Screenshot-2020-09-21-at-9.40.01-AM.png\" width=\"400\" \n",
    "     height=\"250\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eLdIl2vsunJX"
   },
   "source": [
    "# Finding Maxima and Minima of a Function:\n",
    "\n",
    "### Calculating Maxima and Minima for a function with a single variable(univariate):\n",
    "* Find points that satisfies the equation $f'(x) = 0$. These points are known as critical points. Let's say you get two points c1 and c2.\n",
    "* Find double derivative of $f''(x)$ and find its value at c1 and c2\n",
    "    * for c1 if -\n",
    "        * f''(c1) > 0 $\\Rightarrow$ its a point of minima and f(c1) is the minimum value\n",
    "        * f''(c1) < 0 $\\Rightarrow$ its a point of maxima and f(c1) is the maximum value\n",
    "        * f''(c1) = 0 $\\Rightarrow$ its a point of inflection.\n",
    "* Similarly, for c2 also we can follow above steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DmdGlEdvUsX"
   },
   "source": [
    "#### Calculating Maxima and Minima for a function with two variable(multivariate):\n",
    "* Let $f(x,y)$ is a bivariate function whose local minima or maxima point needs to be calculated.\n",
    "* Find - \n",
    "    * $f_x = p = \\frac{\\partial{f}}{\\partial{x}}$ and \n",
    "    * $f_y = q = \\frac{\\partial{f}}{\\partial{y}}$.\n",
    "* Solve $f_x = 0$ and $f_y = 0$ and find stationary or critical points.\n",
    "* Find - \n",
    "    * $r = f_{xx} = \\frac{\\partial{f}^2}{\\partial{x}^2}$, \n",
    "    * $s = f_{xy} = \\frac{\\partial{f}^2}{\\partial{xy}}$ and \n",
    "    * $t = f_{yy} = \\frac{\\partial{f}^2}{\\partial{y}^2}$\n",
    "* Lets do the analysis for the critical points that we have obtained. Lets take a critical point (a,b)\n",
    "    * if $r.t - s^2 > 0$ and\n",
    "        * if $r > 0$ $\\Rightarrow$ $f(a,b)$ has local minimum at that critical point\n",
    "        * if $r < 0$ $\\Rightarrow$ $f(a,b)$ has local maximum at that critical point\n",
    "    * if $r.t - s^2 = 0$ $\\Rightarrow$ test fails.\n",
    "    * if $r.t - s^2 < 0$ $\\Rightarrow$ its a sadal point at the critical point (i.e. neither max nor minimum) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
