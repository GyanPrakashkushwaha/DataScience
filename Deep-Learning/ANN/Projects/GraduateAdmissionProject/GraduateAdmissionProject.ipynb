{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduate Admission Regression Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense , Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping # to stop without completing all epochs\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')\n",
    "df.drop(columns='Serial No.',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          500 non-null    int64  \n",
      " 1   TOEFL Score        500 non-null    int64  \n",
      " 2   University Rating  500 non-null    int64  \n",
      " 3   SOP                500 non-null    float64\n",
      " 4   LOR                500 non-null    float64\n",
      " 5   CGPA               500 non-null    float64\n",
      " 6   Research           500 non-null    int64  \n",
      " 7   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent and independent features\n",
    "X = df.drop('Chance of Admit',axis=1)\n",
    "y = df['Chance of Admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>316</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>314</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>308</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>302</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research\n",
       "249        321          111                  3  3.5  4.0  8.83         1\n",
       "433        316          111                  4  4.0  5.0  8.54         0\n",
       "19         303          102                  3  3.5  3.0  8.50         0\n",
       "322        314          107                  2  2.5  4.0  8.27         0\n",
       "332        308          106                  3  3.5  2.5  8.21         1\n",
       "..         ...          ...                ...  ...  ...   ...       ...\n",
       "106        329          111                  4  4.5  4.5  9.18         1\n",
       "270        306          105                  2  2.5  3.0  8.22         1\n",
       "348        302           99                  1  2.0  2.0  7.25         0\n",
       "435        309          105                  2  2.5  4.0  7.68         0\n",
       "102        314          106                  2  4.0  3.5  8.25         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmaxscale = MinMaxScaler()\n",
    "X_train = minmaxscale.fit_transform(X_train)\n",
    "X_test = minmaxscale.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation= 'relu',input_dim = 7))\n",
    "model.add(Dense(1,activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 1s 31ms/step - loss: 1.1188 - accuracy: 0.0000e+00 - val_loss: 0.8905 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.0000e+00 - val_loss: 0.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.0000e+00 - val_loss: 0.2453 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.0000e+00 - val_loss: 0.1255 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.0000e+00 - val_loss: 0.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.0000e+00 - val_loss: 0.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0732 - accuracy: 0.0000e+00 - val_loss: 0.0839 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0719 - accuracy: 0.0000e+00 - val_loss: 0.0824 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.0000e+00 - val_loss: 0.0799 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.0000e+00 - val_loss: 0.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0000e+00 - val_loss: 0.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0000e+00 - val_loss: 0.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0000e+00 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0000e+00 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.0000e+00 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.0000e+00 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.0000e+00 - val_loss: 0.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.0000e+00 - val_loss: 0.0638 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.0000e+00 - val_loss: 0.0622 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.0000e+00 - val_loss: 0.0607 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.0000e+00 - val_loss: 0.0592 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.0000e+00 - val_loss: 0.0577 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.0000e+00 - val_loss: 0.0561 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.0000e+00 - val_loss: 0.0547 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0531 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.0000e+00 - val_loss: 0.0515 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.0000e+00 - val_loss: 0.0503 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.0000e+00 - val_loss: 0.0489 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.0000e+00 - val_loss: 0.0480 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.0000e+00 - val_loss: 0.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.0000e+00 - val_loss: 0.0456 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.0000e+00 - val_loss: 0.0443 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.0000e+00 - val_loss: 0.0433 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0421 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.0000e+00 - val_loss: 0.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.0000e+00 - val_loss: 0.0405 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.0000e+00 - val_loss: 0.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.0000e+00 - val_loss: 0.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.0000e+00 - val_loss: 0.0381 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.0000e+00 - val_loss: 0.0373 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.0000e+00 - val_loss: 0.0365 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.0000e+00 - val_loss: 0.0347 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.0000e+00 - val_loss: 0.0340 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0333 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0328 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0323 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0317 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0308 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0303 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0299 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0294 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0286 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0281 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0266 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0263 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0205 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0253 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.0000e+00 - val_loss: 0.0244 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0182 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0220 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.0000e+00 - val_loss: 0.0212 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.0000e+00 - val_loss: 0.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0206 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.0000e+00 - val_loss: 0.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.0000e+00 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.0000e+00 - val_loss: 0.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.0000e+00 - val_loss: 0.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0194 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.0000e+00 - val_loss: 0.0191 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0189 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.0000e+00 - val_loss: 0.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0185 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0183 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0181 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0176 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0173 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0160 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0153 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0137 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 424: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=500,validation_split=0.2,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14b0b32c8d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1900x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(nrows=1,ncols=2,figsize = (19,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['validation accuracy','traning accuracy'])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(['validation loss','traning loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
