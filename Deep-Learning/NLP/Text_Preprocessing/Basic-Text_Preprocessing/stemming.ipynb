{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### in stemming we get that words which are not of the word of english\n",
    "> ### Stemming is usefull when we don't have to show the OUTPUT to the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(txt):\n",
    "    return \" \".join([ps.stem(word=word) for word in txt.split()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word before stemming -[walk] after stemming - [walk]\n",
      "word before stemming -[walks] after stemming - [walk]\n",
      "word before stemming -[walking] after stemming - [walk]\n",
      "word before stemming -[walked] after stemming - [walk]\n"
     ]
    }
   ],
   "source": [
    "txt = 'walk walks walking walked'\n",
    "for word in txt.split():\n",
    "    print(f'word before stemming -[{word}] after stemming - [{ps.stem(word)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'walk walks walking walked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(txt=txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = 'Stemming is a linguistic technique used in natural language processing and information retrieval to reduce words to their base or root form, known as a stem. The process involves removing suffixes and sometimes prefixes from words, aiming to unify different grammatical forms of a word. Stemming can be beneficial in various text analysis tasks, such as text classification, information retrieval, and sentiment analysis. By reducing words to their stems, stemming allows for better matching of words and reduces the vocabulary size, which can improve computational efficiency. However, its important to note that stemming may not always produce accurate results since it operates based on predefined rules rather than context. Therefore, its essential to consider the limitations of stemming algorithms and explore other techniques, such as lemmatization or more advanced language models, depending on the specific requirements of the task at hand.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming            stem                \n",
      "is                  is                  \n",
      "a                   a                   \n",
      "linguistic          linguist            \n",
      "technique           techniqu            \n",
      "used                use                 \n",
      "in                  in                  \n",
      "natural             natur               \n",
      "language            languag             \n",
      "processing          process             \n",
      "and                 and                 \n",
      "information         inform              \n",
      "retrieval           retriev             \n",
      "to                  to                  \n",
      "reduce              reduc               \n",
      "words               word                \n",
      "to                  to                  \n",
      "their               their               \n",
      "base                base                \n",
      "or                  or                  \n",
      "root                root                \n",
      "form,               form,               \n",
      "known               known               \n",
      "as                  as                  \n",
      "a                   a                   \n",
      "stem.               stem.               \n",
      "The                 the                 \n",
      "process             process             \n",
      "involves            involv              \n",
      "removing            remov               \n",
      "suffixes            suffix              \n",
      "and                 and                 \n",
      "sometimes           sometim             \n",
      "prefixes            prefix              \n",
      "from                from                \n",
      "words,              words,              \n",
      "aiming              aim                 \n",
      "to                  to                  \n",
      "unify               unifi               \n",
      "different           differ              \n",
      "grammatical         grammat             \n",
      "forms               form                \n",
      "of                  of                  \n",
      "a                   a                   \n",
      "word.               word.               \n",
      "Stemming            stem                \n",
      "can                 can                 \n",
      "be                  be                  \n",
      "beneficial          benefici            \n",
      "in                  in                  \n",
      "various             variou              \n",
      "text                text                \n",
      "analysis            analysi             \n",
      "tasks,              tasks,              \n",
      "such                such                \n",
      "as                  as                  \n",
      "text                text                \n",
      "classification,     classification,     \n",
      "information         inform              \n",
      "retrieval,          retrieval,          \n",
      "and                 and                 \n",
      "sentiment           sentiment           \n",
      "analysis.           analysis.           \n",
      "By                  by                  \n",
      "reducing            reduc               \n",
      "words               word                \n",
      "to                  to                  \n",
      "their               their               \n",
      "stems,              stems,              \n",
      "stemming            stem                \n",
      "allows              allow               \n",
      "for                 for                 \n",
      "better              better              \n",
      "matching            match               \n",
      "of                  of                  \n",
      "words               word                \n",
      "and                 and                 \n",
      "reduces             reduc               \n",
      "the                 the                 \n",
      "vocabulary          vocabulari          \n",
      "size,               size,               \n",
      "which               which               \n",
      "can                 can                 \n",
      "improve             improv              \n",
      "computational       comput              \n",
      "efficiency.         efficiency.         \n",
      "However,            however,            \n",
      "its                 it                  \n",
      "important           import              \n",
      "to                  to                  \n",
      "note                note                \n",
      "that                that                \n",
      "stemming            stem                \n",
      "may                 may                 \n",
      "not                 not                 \n",
      "always              alway               \n",
      "produce             produc              \n",
      "accurate            accur               \n",
      "results             result              \n",
      "since               sinc                \n",
      "it                  it                  \n",
      "operates            oper                \n",
      "based               base                \n",
      "on                  on                  \n",
      "predefined          predefin            \n",
      "rules               rule                \n",
      "rather              rather              \n",
      "than                than                \n",
      "context.            context.            \n",
      "Therefore,          therefore,          \n",
      "its                 it                  \n",
      "essential           essenti             \n",
      "to                  to                  \n",
      "consider            consid              \n",
      "the                 the                 \n",
      "limitations         limit               \n",
      "of                  of                  \n",
      "stemming            stem                \n",
      "algorithms          algorithm           \n",
      "and                 and                 \n",
      "explore             explor              \n",
      "other               other               \n",
      "techniques,         techniques,         \n",
      "such                such                \n",
      "as                  as                  \n",
      "lemmatization       lemmat              \n",
      "or                  or                  \n",
      "more                more                \n",
      "advanced            advanc              \n",
      "language            languag             \n",
      "models,             models,             \n",
      "depending           depend              \n",
      "on                  on                  \n",
      "the                 the                 \n",
      "specific            specif              \n",
      "requirements        requir              \n",
      "of                  of                  \n",
      "the                 the                 \n",
      "task                task                \n",
      "at                  at                  \n",
      "hand.               hand.               \n"
     ]
    }
   ],
   "source": [
    "txt = paragraph\n",
    "for word in txt.split():\n",
    "    # print(f'{1:20} {1:20} [{word}][{ps.stem(word)}]')\n",
    "    print('{0:20}{1:20}'.format(word,ps.stem(word)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Here I am getting those words which don't have meaning in ENGLISH "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### in Lemmatization we get the actual words\n",
    "> ### Lemmatization is usefull when we have to show the OUTPUT to the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = 'Stemming is a linguistic technique used in natural language processing and information retrieval to reduce words to their base or root form, known as a stem. The process involves removing suffixes and sometimes prefixes from words, aiming to unify different grammatical forms of a word. Stemming can be beneficial in various text analysis tasks, such as text classification, information retrieval, and sentiment analysis. By reducing words to their stems, stemming allows for better matching of words and reduces the vocabulary size, which can improve computational efficiency. However, its important to note that stemming may not always produce accurate results since it operates based on predefined rules rather than context. Therefore, its essential to consider the limitations of stemming algorithms and explore other techniques, such as lemmatization or more advanced language models, depending on the specific requirements of the task at hand.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming            Stemming            \n",
      "is                  is                  \n",
      "a                   a                   \n",
      "linguistic          linguistic          \n",
      "technique           technique           \n",
      "used                used                \n",
      "in                  in                  \n",
      "natural             natural             \n",
      "language            language            \n",
      "processing          processing          \n",
      "and                 and                 \n",
      "information         information         \n",
      "retrieval           retrieval           \n",
      "to                  to                  \n",
      "reduce              reduce              \n",
      "words               word                \n",
      "to                  to                  \n",
      "their               their               \n",
      "base                base                \n",
      "or                  or                  \n",
      "root                root                \n",
      "form,               form,               \n",
      "known               known               \n",
      "as                  a                   \n",
      "a                   a                   \n",
      "stem.               stem.               \n",
      "The                 The                 \n",
      "process             process             \n",
      "involves            involves            \n",
      "removing            removing            \n",
      "suffixes            suffix              \n",
      "and                 and                 \n",
      "sometimes           sometimes           \n",
      "prefixes            prefix              \n",
      "from                from                \n",
      "words,              words,              \n",
      "aiming              aiming              \n",
      "to                  to                  \n",
      "unify               unify               \n",
      "different           different           \n",
      "grammatical         grammatical         \n",
      "forms               form                \n",
      "of                  of                  \n",
      "a                   a                   \n",
      "word.               word.               \n",
      "Stemming            Stemming            \n",
      "can                 can                 \n",
      "be                  be                  \n",
      "beneficial          beneficial          \n",
      "in                  in                  \n",
      "various             various             \n",
      "text                text                \n",
      "analysis            analysis            \n",
      "tasks,              tasks,              \n",
      "such                such                \n",
      "as                  a                   \n",
      "text                text                \n",
      "classification,     classification,     \n",
      "information         information         \n",
      "retrieval,          retrieval,          \n",
      "and                 and                 \n",
      "sentiment           sentiment           \n",
      "analysis.           analysis.           \n",
      "By                  By                  \n",
      "reducing            reducing            \n",
      "words               word                \n",
      "to                  to                  \n",
      "their               their               \n",
      "stems,              stems,              \n",
      "stemming            stemming            \n",
      "allows              allows              \n",
      "for                 for                 \n",
      "better              better              \n",
      "matching            matching            \n",
      "of                  of                  \n",
      "words               word                \n",
      "and                 and                 \n",
      "reduces             reduces             \n",
      "the                 the                 \n",
      "vocabulary          vocabulary          \n",
      "size,               size,               \n",
      "which               which               \n",
      "can                 can                 \n",
      "improve             improve             \n",
      "computational       computational       \n",
      "efficiency.         efficiency.         \n",
      "However,            However,            \n",
      "its                 it                  \n",
      "important           important           \n",
      "to                  to                  \n",
      "note                note                \n",
      "that                that                \n",
      "stemming            stemming            \n",
      "may                 may                 \n",
      "not                 not                 \n",
      "always              always              \n",
      "produce             produce             \n",
      "accurate            accurate            \n",
      "results             result              \n",
      "since               since               \n",
      "it                  it                  \n",
      "operates            operates            \n",
      "based               based               \n",
      "on                  on                  \n",
      "predefined          predefined          \n",
      "rules               rule                \n",
      "rather              rather              \n",
      "than                than                \n",
      "context.            context.            \n",
      "Therefore,          Therefore,          \n",
      "its                 it                  \n",
      "essential           essential           \n",
      "to                  to                  \n",
      "consider            consider            \n",
      "the                 the                 \n",
      "limitations         limitation          \n",
      "of                  of                  \n",
      "stemming            stemming            \n",
      "algorithms          algorithm           \n",
      "and                 and                 \n",
      "explore             explore             \n",
      "other               other               \n",
      "techniques,         techniques,         \n",
      "such                such                \n",
      "as                  a                   \n",
      "lemmatization       lemmatization       \n",
      "or                  or                  \n",
      "more                more                \n",
      "advanced            advanced            \n",
      "language            language            \n",
      "models,             models,             \n",
      "depending           depending           \n",
      "on                  on                  \n",
      "the                 the                 \n",
      "specific            specific            \n",
      "requirements        requirement         \n",
      "of                  of                  \n",
      "the                 the                 \n",
      "task                task                \n",
      "at                  at                  \n",
      "hand.               hand.               \n"
     ]
    }
   ],
   "source": [
    "txt = paragraph\n",
    "for word in txt.split():\n",
    "    # print(f'{1:20} {1:20} [{word}][{ps.stem(word)}]')\n",
    "    print('{0:20}{1:20}'.format(word,lemmatizer.lemmatize(word=word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
