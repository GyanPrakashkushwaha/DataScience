{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer # this is for tokenizing like -> \"I\"- 1 ,\"love\"- 2 ,\"deep\"- 3 ,\"learning\"- 4\n",
    "from keras.utils import pad_sequences # Since I have different sequences in sequence so that we use padding. if we use padding we actually give 0 values for sequence which have less counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['go india',\n",
    "\t\t'india india',\n",
    "\t\t'hip hip hurray',\n",
    "\t\t'jeetega bhai jeetega india jeetega',\n",
    "\t\t'bharat mata ki jai',\n",
    "\t\t'kohli kohli',\n",
    "\t\t'sachin sachin',\n",
    "\t\t'dhoni dhoni',\n",
    "\t\t'modi ji ki jai',\n",
    "\t\t'inquilab zindabad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x240add39510>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='GyanPrakash'   # this oov_token is for when my model will get an text which he have not seen in training than this will replace text with oov_token\n",
    "                      ) \n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer.fit_on_texts(texts=texts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GyanPrakash': 1,\n",
       " 'india': 2,\n",
       " 'jeetega': 3,\n",
       " 'hip': 4,\n",
       " 'ki': 5,\n",
       " 'jai': 6,\n",
       " 'kohli': 7,\n",
       " 'sachin': 8,\n",
       " 'dhoni': 9,\n",
       " 'go': 10,\n",
       " 'hurray': 11,\n",
       " 'bhai': 12,\n",
       " 'bharat': 13,\n",
       " 'mata': 14,\n",
       " 'modi': 15,\n",
       " 'ji': 16,\n",
       " 'inquilab': 17,\n",
       " 'zindabad': 18}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for unique words and which index is tokenizer is assigning.\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('go', 1),\n",
       "             ('india', 4),\n",
       "             ('hip', 2),\n",
       "             ('hurray', 1),\n",
       "             ('jeetega', 3),\n",
       "             ('bhai', 1),\n",
       "             ('bharat', 1),\n",
       "             ('mata', 1),\n",
       "             ('ki', 2),\n",
       "             ('jai', 2),\n",
       "             ('kohli', 2),\n",
       "             ('sachin', 2),\n",
       "             ('dhoni', 2),\n",
       "             ('modi', 1),\n",
       "             ('ji', 1),\n",
       "             ('inquilab', 1),\n",
       "             ('zindabad', 1)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this shows frequency of the word\n",
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is used for sentence count\n",
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[10, 2],\n",
       "  [2, 2],\n",
       "  [4, 4, 11],\n",
       "  [3, 12, 3, 2, 3],\n",
       "  [13, 14, 5, 6],\n",
       "  [7, 7],\n",
       "  [8, 8],\n",
       "  [9, 9],\n",
       "  [15, 16, 5, 6],\n",
       "  [17, 18]],\n",
       " {'GyanPrakash': 1,\n",
       "  'india': 2,\n",
       "  'jeetega': 3,\n",
       "  'hip': 4,\n",
       "  'ki': 5,\n",
       "  'jai': 6,\n",
       "  'kohli': 7,\n",
       "  'sachin': 8,\n",
       "  'dhoni': 9,\n",
       "  'go': 10,\n",
       "  'hurray': 11,\n",
       "  'bhai': 12,\n",
       "  'bharat': 13,\n",
       "  'mata': 14,\n",
       "  'modi': 15,\n",
       "  'ji': 16,\n",
       "  'inquilab': 17,\n",
       "  'zindabad': 18})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to make the words in sequence\n",
    "sequences = tokenizer.texts_to_sequences(texts=texts)\n",
    "sequences , tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  2  0  0  0]\n",
      " [ 2  2  0  0  0]\n",
      " [ 4  4 11  0  0]\n",
      " [ 3 12  3  2  3]\n",
      " [13 14  5  6  0]\n",
      " [ 7  7  0  0  0]\n",
      " [ 8  8  0  0  0]\n",
      " [ 9  9  0  0  0]\n",
      " [15 16  5  6  0]\n",
      " [17 18  0  0  0]]\n",
      "Now my data is ready for training\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences=sequences,padding='post')\n",
    "print(sequences)\n",
    "print('Now my data is ready for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
